{
    "general" :{
        "batch_size": 2048,
        "latent_size": 20,
        "lr": 0.00001,
        "num_epochs": 100
    },
    "encoder":{
        "layer_num": 5,
        "architecture": [[512], [512, 1024], [1024, 2048], [2048, 2048], [2048]],
        "batchNorm": [512, 1024, 2048, 2048, 0],
        "relu":[1, 1, 1, 1, 0],
        "dropout": [0.0, 0.0, 0.0,0, 0]
    },
    "decoder":{
        "layer_num": 5,
        "architecture": [[2048], [2048, 2048], [2048, 1024], [1024, 512], [512]],
        "batchNorm": [2048, 2048, 1024, 512, 0],
        "relu":[1, 1, 1, 1, 0],
        "dropout": [0, 0, 0, 0, 0]
    }
}